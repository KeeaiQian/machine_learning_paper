## Contrastive learning for label-efficient semanti segmentation

Introduction: Introduction to contrastive learning.

paper: https://arxiv.org/pdf/2012.06985v2.pdf

## Contrastive learning of global and local features for medical image segmentation with limited annotations

Introduction: Use contrastive learning to perform unsupervised pretraining on networks with encoder-decoder structure.

paper: https://papers.nips.cc/paper/2020/file/949686ecef4ee20a62d16b4a2d7ccca3-Paper.pdf

code: https://github.com/krishnabits001/domain_specific_cl

## Semi-supervised semantic segmentation with cross pseudo supervision

Introduction: If you happen to use two sets of parameters when you do contrastive pretraining. Can also be used when we only have a small proportion of
data labeled.

paper: https://arxiv.org/pdf/2106.01226.pdf

## Unsupervised domain adaptation for medical imaging segmentation with self-ensembling

Introduction: A way to make model more generalized for different scenarios. But I think this can already be achieved by self-supervised learning with data augmentation? Not sure whether this methid will work better.

paper: https://arxiv.org/pdf/1811.06042.pdf

## A comparison of linear genetic programming and neural networks in medical data mining

Abstract: We introduce a new form of linear genetic programming (GP). Two methods of acceleration of our GP approach are discussed: 1) an efficient algorithm that eliminates intron code and 2) a demetic approach to virtually parallelize the system on a single processor. Acceleration of runtime is especially important when operating with complex data sets, because they are occurring in real-world applications. We compare GP performance on medical classification problems from a benchmark database with results obtained by neural networks. Our results show that GP performs comparably in classification and generalization.

paper: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=910462
